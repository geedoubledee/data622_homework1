---
title: "DATA 622 - Homework 1"
author: "Glen Dale Davis"
date: "2024-03-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r packages, warning = FALSE, message = FALSE}
library(caret)
library(DataExplorer)
library(knitr)
library(naniar)
library(RColorBrewer)
library(stopwords)
library(tidytext)
library(tidyverse)

```

## Introduction

We load two labeled text datasets of very different sizes, which we will use to train three different models to classify text based on sentiment and emotion.

* In the small dataset, social media messages from Twitter, Facebook, and Instagram have been classified as primarily conveying positive, negative, or neutral sentiment; our response variable for this dataset will be `SENTIMENT`

* In the large dataset, Twitter messages have been classified as primarily conveying one of six emotions: sadness, joy, love, anger, fear, and surprise; our response variable for this dataset will be `EMOTION`

While the only feature in the large dataset is the text of the message itself, the small dataset has additional features related to the time and date the message was sent, as well as the platform used to send it since the small dataset covers more social media platforms than the large dataset. 

## Exploratory Data Analysis

We look at summaries of the datasets to confirm the numbers of observations in each and whether there are any missing values to address. 

```{r data1}
my_url1 <- "https://raw.githubusercontent.com/geedoubledee/data622_homework1/main/sentiment_analysis.csv"
small_df <- read.csv(my_url1)
cols <- c("YEAR", "MONTH", "DAY", "TIME", "TXT", "SENTIMENT", "PLATFORM")
colnames(small_df) <- cols
char_cols <- colnames(small_df[, sapply(small_df, class) == "character"])
small_df_sub1 <- small_df |>
    select(-all_of(char_cols))
small_df_sub2 <- small_df |>
    select(all_of(char_cols)) |>
    sapply(str_trim) |>
    as.data.frame()
small_df <- small_df_sub1 |>
    bind_cols(small_df_sub2) |>
    rowid_to_column(var = "ID")
remove <- c("total_observations", "memory_usage")
reorder <- c("rows", "complete_rows", "columns", "discrete_columns",
             "continuous_columns", "all_missing_columns",
             "total_missing_values")
introduce <- small_df |>
    introduce() |>
    select(-all_of(remove))
introduce <- introduce[, reorder]
knitr::kable(t(introduce), format = "simple")

```

There are less than 500 observations in the small dataset. 

```{r data2}
my_url2 <- "https://raw.githubusercontent.com/geedoubledee/data622_homework1/main/text_pt_"
x <- seq(1, 9)
y <- rep(".csv", 9)
files <- paste0(x, y)
cols <- c("TXT", "LAB")
large_df <- as.data.frame(matrix(nrow = 0, ncol = 2))
colnames(large_df) <- cols
large_df <- large_df |>
    mutate(TXT = as.character(TXT),
           LAB = as.integer(LAB))
for (f in files){
    new_rows <- read.csv(paste0(my_url2, f))
    colnames(new_rows) <- cols
    large_df <- large_df |>
        bind_rows(new_rows)
}
large_df <- large_df |>
    rowid_to_column(var = "ID")
rm(new_rows)
my_url3 <- "https://raw.githubusercontent.com/geedoubledee/data622_homework1/main/text_label_map.csv"
txt_lab_map <- read.csv(my_url3)
cols <- c("KEY", "EMOTION")
colnames(txt_lab_map) <- cols
large_df <- large_df |>
    left_join(txt_lab_map, by = join_by(LAB == KEY),
              relationship = "many-to-one")
remove <- c("total_observations", "memory_usage")
reorder <- c("rows", "complete_rows", "columns", "discrete_columns",
             "continuous_columns", "all_missing_columns",
             "total_missing_values")
introduce <- large_df |>
    introduce() |>
    select(-all_of(remove))
introduce <- introduce[, reorder]
knitr::kable(t(introduce), format = "simple")

```

And there are over 400,000 observations in the large dataset. There are no missing values to address in either dataset, so now we take a look at the distributions of our response variables:

* `SENTIMENT` in the small dataset

* `EMOTION` in the large dataset

```{r plot1, warning = FALSE, message = FALSE}
cur_theme = theme_set(theme_classic())
palette1 <- brewer.pal(8, "Dark2")
palette2 <- brewer.pal(11, "RdYlBu")
cols <- palette2[c(2, 6, 10)]
names(cols) <- c("negative", "neutral", "positive")
fils <- cols
obs = nrow(small_df)
p1 <- small_df |>
    ggplot(aes(x = SENTIMENT)) +
    geom_histogram(aes(color = SENTIMENT, fill = SENTIMENT), stat = "count") +
    geom_text(stat = "count", aes(label = paste0(round(
        after_stat(count) / obs * 100, 1), "%")),
              size = 4, color = "black", nudge_y = 8) + 
    scale_color_manual(values = cols) +
    scale_fill_manual(values = fils) +
    labs(title = "Distribution of SENTIMENT in the Small Dataset",
         y = "COUNT") +
    theme(legend.position = "none")
p1

```

In the small dataset, the most frequent `SENTIMENT` class is neutral, followed by positive, then negative. There are some slight class imbalances here, but since we'll be doing text analysis, our input variables will primarily be categorical, and using the SMOTE algorithm to fix unbalanced classification problems is therefore not recommended. None of the classes is so rare that we should be worried about the predictive power of any of the models we'll be developing.

```{r plot2, warning = FALSE, message = FALSE}
cols <- palette1[1:6]
names(cols) <- c("sadness", "joy", "love", "anger", "fear", "surprise")
fils <- cols
obs <- nrow(large_df)
p2 <- large_df |>
    ggplot(aes(x = EMOTION)) +
    geom_histogram(aes(color = EMOTION, fill = EMOTION), stat = "count") +
    geom_text(stat = "count", aes(label = paste0(round(
        after_stat(count) / obs * 100, 1), "%")),
              size = 4, color = "white", hjust = 1.1, fontface = "bold") + 
    scale_color_manual(values = cols) +
    scale_fill_manual(values = fils) +
    labs(title = "Distribution of EMOTION in the Large Dataset",
         y = "COUNT") +
    coord_flip() +
    theme(legend.position = "none")
p2

```

In the large dataset, we see a worse class imbalance issue. Joy is the most frequent `EMOTION` in the large dataset, and it occurs nearly 10 times as often as the least frequent `EMOTION`: surprise. This will affect the predictive power of some of the models we'll be developing since we again can't use SMOTE to correct the issue, but one of the models is actually well suited for overcoming it. 

## Data Preparation

For text analysis, we need to tokenize our data. 

```{r tokenization1}
small_df_tokens <- small_df |>
    unnest_tokens(output = WORD, input = TXT, strip_punct = TRUE) |>
    anti_join(stop_words, by = join_by(WORD == word)) |>
    filter(!grepl('[0-9]', WORD)) |>
    pivot_wider(id_cols = ID, names_from = WORD, values_from = WORD,
                values_fn = list(WORD = length), values_fill = list(WORD = 0))
small_df <- small_df |>
    left_join(small_df_tokens, by = join_by(ID))
small_df[is.na(small_df)] <- 0

```

```{r tokenization2}

```

## Modeling

```{r modeling1}

```

```{r modeling2}

```

## Conclusion
